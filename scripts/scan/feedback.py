"""Parse, aggregate, and route scope-deltas from deep scan feedback.

Translates the post-scan feedback collection and routing from scan.sh.
"""

from __future__ import annotations

import json
import re
from pathlib import Path

from .dispatch import dispatch_agent, read_scan_model_policy
from .exploration import apply_related_files_update

_TEMPLATES = Path(__file__).resolve().parent / "templates"


def _load_template(name: str) -> str:
    return (_TEMPLATES / name).read_text()


def collect_and_route_feedback(
    *,
    section_files: list[Path],
    codemap_path: Path,
    codespace: Path,
    artifacts_dir: Path,
    scan_log_dir: Path,
    model_policy: dict[str, str] | None = None,
) -> bool:
    """Collect feedback from deep scan, produce report, and route findings.

    Returns ``True`` if any feedback was found.
    """
    if model_policy is None:
        model_policy = read_scan_model_policy(artifacts_dir)
    print("--- Deep Scan: collecting feedback ---")

    feedback_report = artifacts_dir / "scan-feedback.md"
    report_lines = [
        "# Scan Feedback Report\n",
        "\nGenerated by deep scan. Review and apply if needed.\n\n",
    ]

    has_feedback = False

    for section_file in section_files:
        sec_name = section_file.stem
        sec_log_dir = scan_log_dir / sec_name

        irrelevant_files: list[str] = []
        missing_files: list[str] = []
        out_of_scope_items: list[str] = []

        for fb_file in sorted(sec_log_dir.glob("deep-*-feedback.json")):
            try:
                data = json.loads(fb_file.read_text())
            except (json.JSONDecodeError, OSError):
                print(
                    f"[DEEP SCAN] WARNING: Malformed feedback JSON: "
                    f"{fb_file} (section: {sec_name})",
                )
                _append_to_log(
                    scan_log_dir / "failures.log",
                    f"- Malformed feedback: `{fb_file}` (section: {sec_name})",
                )
                # Preserve corrupted file for diagnosis (V2/R55)
                try:
                    fb_file.rename(fb_file.with_suffix(".malformed.json"))
                except OSError:
                    pass  # Best-effort preserve
                continue

            # Schema validation: required fields must be present and typed
            if not _validate_feedback_schema(data, fb_file, sec_name, scan_log_dir):
                continue

            relevant = data["relevant"]
            if relevant is False:
                reason = data.get("reason", "")
                src_path = data["source_file"]
                irrelevant_files.append(f"- {src_path}: {reason}")
                has_feedback = True

            # Collect missing files
            for mf in data.get("missing_files", []):
                if isinstance(mf, str) and mf.strip():
                    missing_files.append(f"- {mf.strip()}")
                    has_feedback = True

            # Collect out-of-scope
            for oos in data.get("out_of_scope", []):
                if isinstance(oos, str) and oos.strip():
                    out_of_scope_items.append(f"- {oos.strip()}")
                    has_feedback = True

        if irrelevant_files or missing_files or out_of_scope_items:
            report_lines.append(f"## {sec_name}\n\n")
            if irrelevant_files:
                report_lines.append(
                    "### Irrelevant files (consider removing)\n",
                )
                report_lines.extend(f"{line}\n" for line in irrelevant_files)
                report_lines.append("\n")
            if missing_files:
                report_lines.append(
                    "### Missing files (consider adding)\n",
                )
                report_lines.extend(f"{line}\n" for line in missing_files)
                report_lines.append("\n")
            if out_of_scope_items:
                report_lines.append(
                    "### Open problems (out of scope for this section)\n",
                )
                report_lines.extend(f"{line}\n" for line in out_of_scope_items)
                report_lines.append("\n")

    if has_feedback:
        feedback_report.write_text("".join(report_lines))
        print(f"[FEEDBACK] Scan feedback written to: {feedback_report}")
    else:
        report_lines.append("## No feedback\n")
        report_lines.append(
            "All files confirmed relevant. No missing files detected.\n",
        )
        feedback_report.write_text("".join(report_lines))

    # Route out-of-scope findings into scope-delta artifacts
    _route_scope_deltas(
        section_files=section_files,
        artifacts_dir=artifacts_dir,
        scan_log_dir=scan_log_dir,
    )

    # Apply feedback (missing + irrelevant files)
    if has_feedback:
        _apply_feedback(
            section_files=section_files,
            codemap_path=codemap_path,
            codespace=codespace,
            artifacts_dir=artifacts_dir,
            scan_log_dir=scan_log_dir,
            model_policy=model_policy,
        )

    return has_feedback


# ------------------------------------------------------------------
# Scope-delta routing
# ------------------------------------------------------------------


def _route_scope_deltas(
    *,
    section_files: list[Path],
    artifacts_dir: Path,
    scan_log_dir: Path,
) -> None:
    """P6: Route out-of-scope findings into scope-delta artifacts."""
    print("--- Deep Scan: routing out-of-scope findings ---")

    scope_deltas_dir = artifacts_dir / "scope-deltas"
    scope_deltas_dir.mkdir(parents=True, exist_ok=True)

    for section_file in section_files:
        sec_name = section_file.stem
        sec_log_dir = scan_log_dir / sec_name
        sec_num = _extract_section_number(sec_name)

        all_oos: list[str] = []
        for fb_file in sorted(sec_log_dir.glob("deep-*-feedback.json")):
            try:
                data = json.loads(fb_file.read_text())
            except (json.JSONDecodeError, OSError) as exc:
                print(
                    f"[SCOPE][WARN] Malformed feedback JSON in "
                    f"scope-delta routing: {fb_file} ({exc})",
                )
                # Preserve corrupted file for diagnosis (V2/R55)
                try:
                    fb_file.rename(fb_file.with_suffix(".malformed.json"))
                except OSError:
                    pass  # Best-effort preserve
                continue
            for item in data.get("out_of_scope", []):
                if isinstance(item, str) and item.strip():
                    all_oos.append(item.strip())

        if not all_oos:
            continue

        delta_path = scope_deltas_dir / f"section-{sec_num}-scope-delta.json"

        # Skip if already adjudicated
        if delta_path.is_file():
            try:
                existing = json.loads(delta_path.read_text())
                if existing.get("adjudicated"):
                    print(
                        f"[SCOPE] section-{sec_num}: scope delta "
                        "already adjudicated — skipping",
                    )
                    continue
            except (json.JSONDecodeError, OSError) as exc:
                # Preserve corrupted scope-delta for diagnosis
                malformed_path = (
                    scope_deltas_dir
                    / f"section-{sec_num}-scope-delta.malformed.json"
                )
                try:
                    delta_path.rename(malformed_path)
                except OSError:
                    pass  # Best-effort preserve
                print(
                    f"[SCOPE][WARN] section-{sec_num}: malformed "
                    f"scope-delta JSON preserved as "
                    f"{malformed_path.name} ({exc})",
                )

        delta = {
            "section": sec_num,
            "origin": "scan-deep",
            "items": all_oos,
            "adjudicated": False,
        }
        delta_path.write_text(json.dumps(delta, indent=2))
        print(
            f"[SCOPE] section-{sec_num}: {len(all_oos)} out-of-scope "
            "items routed to scope-deltas",
        )


# ------------------------------------------------------------------
# Feedback application (P10+P3)
# ------------------------------------------------------------------


def _apply_feedback(
    *,
    section_files: list[Path],
    codemap_path: Path,
    codespace: Path,
    artifacts_dir: Path,
    scan_log_dir: Path,
    model_policy: dict[str, str],
) -> None:
    """Apply missing files and prune irrelevant files from feedback."""
    print("--- Deep Scan: applying feedback (missing + irrelevant files) ---")

    corrections_path = artifacts_dir / "signals" / "codemap-corrections.json"
    corrections_ref = ""
    if corrections_path.is_file():
        corrections_ref = (
            f"\n3. Codemap corrections (authoritative fixes): "
            f"`{corrections_path}`"
        )

    for section_file in section_files:
        sec_name = section_file.stem
        sec_log_dir = scan_log_dir / sec_name
        section_text = section_file.read_text()

        all_missing: list[str] = []
        all_irrelevant: list[str] = []

        for fb_file in sorted(sec_log_dir.glob("deep-*-feedback.json")):
            try:
                data = json.loads(fb_file.read_text())
            except (json.JSONDecodeError, OSError) as exc:
                print(
                    f"[FEEDBACK][WARN] Malformed feedback JSON in "
                    f"apply_feedback: {fb_file} ({exc})",
                )
                # Preserve corrupted file for diagnosis (V2/R55)
                try:
                    fb_file.rename(fb_file.with_suffix(".malformed.json"))
                except OSError:
                    pass  # Best-effort preserve
                continue

            # Skip entries with missing required fields
            if not isinstance(data.get("relevant"), bool):
                continue
            if not isinstance(data.get("source_file"), str):
                continue

            # Collect missing
            for mf in data.get("missing_files", []):
                if isinstance(mf, str) and mf.strip():
                    all_missing.append(mf.strip())

            # Collect irrelevant
            if data["relevant"] is False:
                irr_path = data["source_file"]
                if irr_path:
                    all_irrelevant.append(irr_path)

        # Filter missing to those not already in the section
        truly_missing = [
            mf for mf in all_missing if f"### {mf}" not in section_text
        ]

        # Filter irrelevant to those actually in the section
        truly_irrelevant = [
            irf for irf in all_irrelevant if f"### {irf}" in section_text
        ]

        if not truly_missing and not truly_irrelevant:
            continue

        print(
            f"[FEEDBACK] {sec_name}: {len(truly_missing)} missing, "
            f"{len(truly_irrelevant)} irrelevant",
        )

        # Dispatch updater agent
        updater_prompt = sec_log_dir / "related-files-updater-prompt.md"
        updater_output = sec_log_dir / "related-files-updater-output.md"
        updater_signal = (
            artifacts_dir / "signals" / f"{sec_name}-related-files-update.json"
        )

        missing_section = ""
        if truly_missing:
            items = "\n".join(f"- {mf}" for mf in truly_missing)
            missing_section = (
                f"## Missing Files Discovered by Deep Scan\n{items}\n\n"
            )

        irrelevant_section = ""
        if truly_irrelevant:
            items = "\n".join(f"- {irf}" for irf in truly_irrelevant)
            irrelevant_section = (
                f"## Irrelevant Files Identified by Deep Scan\n{items}\n\n"
                "These files were judged irrelevant to this section's "
                "concern by deep scan.\nOnly include them in removals if "
                "you agree they are unrelated to the\nsection's problem "
                "frame. Give a short reason for each removal.\n\n"
            )

        prompt = _load_template("related_files_updater.md").format(
            section_name=sec_name,
            section_file=section_file,
            codemap_path=codemap_path,
            corrections_ref=corrections_ref,
            missing_section=missing_section,
            irrelevant_section=irrelevant_section,
            updater_signal=updater_signal,
        )
        updater_prompt.write_text(prompt)

        updater_model = model_policy.get("feedback_updater", "glm")
        escalation_model = model_policy.get("exploration", "claude-opus")
        result = dispatch_agent(
            model=updater_model,
            project=codespace,
            prompt_file=updater_prompt,
            stdout_file=updater_output,
        )

        # Check if signal is valid; escalate on failure
        if result.returncode == 0 and updater_signal.is_file():
            valid_signal = _is_valid_updater_signal(updater_signal)
        else:
            valid_signal = False

        if not valid_signal and result.returncode == 0:
            print(
                f"[FEEDBACK] {sec_name}: {updater_model} updater produced "
                f"no valid signal — escalating to {escalation_model}",
            )
            result = dispatch_agent(
                model=escalation_model,
                project=codespace,
                prompt_file=updater_prompt,
                stdout_file=updater_output,
            )
            valid_signal = (
                result.returncode == 0
                and updater_signal.is_file()
                and _is_valid_updater_signal(updater_signal)
            )

        if not valid_signal:
            if result.returncode != 0:
                _append_to_log(
                    scan_log_dir / "failures.log",
                    f"- Updater failed for {sec_name} (no valid signal "
                    "after escalation)",
                )
            continue

        try:
            sig_data = json.loads(updater_signal.read_text())
            status = sig_data.get("status", "")
        except (json.JSONDecodeError, OSError) as exc:
            print(
                f"[FEEDBACK][WARN] Malformed updater signal: "
                f"{updater_signal} ({exc})",
            )
            # Preserve corrupted signal for diagnosis (V3/R56)
            try:
                updater_signal.rename(
                    updater_signal.with_suffix(".malformed.json"))
            except OSError:
                pass  # Best-effort preserve
            continue

        if status == "stale":
            applied = apply_related_files_update(
                section_file, updater_signal)
            # Acknowledge the signal — update status so it isn't
            # re-applied on subsequent runs.
            try:
                sig_data["status"] = "applied" if applied else "no_change"
                updater_signal.write_text(
                    json.dumps(sig_data, indent=2), encoding="utf-8")
            except OSError:
                pass  # Best-effort ack; signal file may be read-only
            if applied:
                print(
                    f"[FEEDBACK] {sec_name}: related files updated "
                    "from deep scan feedback",
                )


# ------------------------------------------------------------------
# Helpers
# ------------------------------------------------------------------


def _is_valid_updater_signal(signal_path: Path) -> bool:
    """Check if an updater signal file contains valid JSON with status."""
    try:
        data = json.loads(signal_path.read_text())
        return isinstance(data.get("status"), str)
    except (json.JSONDecodeError, OSError):
        return False


def _validate_feedback_schema(
    data: dict,
    fb_file: Path,
    sec_name: str,
    scan_log_dir: Path,
) -> bool:
    """Validate required fields in deep-scan feedback JSON.

    Required: ``relevant`` (bool), ``source_file`` (str).
    Returns ``True`` if valid, ``False`` if missing/wrong type.
    """
    missing: list[str] = []
    if not isinstance(data.get("relevant"), bool):
        missing.append("relevant (must be bool)")
    if not isinstance(data.get("source_file"), str):
        missing.append("source_file (must be str)")

    if missing:
        detail = ", ".join(missing)
        print(
            f"[DEEP SCAN] WARNING: Feedback missing required fields: "
            f"{detail} — {fb_file} (section: {sec_name})",
        )
        _append_to_log(
            scan_log_dir / "failures.log",
            f"- Missing required fields ({detail}): "
            f"`{fb_file}` (section: {sec_name})",
        )
        return False

    # Optional list fields: validate type if present
    for field in ("missing_files", "out_of_scope"):
        val = data.get(field)
        if val is not None and not isinstance(val, list):
            print(
                f"[DEEP SCAN] WARNING: Feedback field '{field}' must be "
                f"list, got {type(val).__name__} — {fb_file}",
            )
            # Coerce to empty list rather than skip entire entry
            data[field] = []

    return True


def _extract_section_number(section_name: str) -> str:
    m = re.search(r"\d+", section_name)
    return m.group(0) if m else ""


def _append_to_log(log_path: Path, message: str) -> None:
    with log_path.open("a") as f:
        f.write(message + "\n")
